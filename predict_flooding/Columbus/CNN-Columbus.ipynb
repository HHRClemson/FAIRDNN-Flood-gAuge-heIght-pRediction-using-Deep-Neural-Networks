{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1becc4d0-aa48-42e2-97c4-550538fd8d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702fa34d-493b-411e-b66b-10ac5ae495df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../../datasets/chattahoochee-columbus.csv',header=0, parse_dates=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d99384d-7f9c-4163-945b-64dad3e3b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/spackages/linux-centos8-x86_64/gcc-8.3.1/anaconda3-2019.10-v5cuhr6keyz5ryxcwvv2jkzfj2gwrj4a/lib/python3.7/site-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1455fcda4810>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "plt.plot(df.index,df[\"height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84b6da5-b7c7-45b9-8971-82ee6ad9a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[:'2020'].iloc[:,:]\n",
    "test_set = df['2021':].iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da42284-7380-412f-8f7d-b49b9c5680d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "training_set_scaled = sc.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecccaa4a-5633-4888-86e8-86e4fd4b8c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210350"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050ac6d7-8bbe-4077-8a06-269c6297c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(100,len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-100:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d938e1d6-1d8e-48e2-aa72-3b56c952ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "223780cc-9f7e-4f37-bd11-a537e07cccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210250, 100, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96091a9c-a00f-49ed-86d1-145a2c9f2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping X_train for efficient modelling\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62a6a62-9cc1-4c1d-b5c7-e993becf4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84abc51a-e30a-4292-b48b-0121676b773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4a6bcf-ba1f-40b7-a576-8f3f5af0c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wape(y, y_pred):\n",
    "    \"\"\"Weighted Average Percentage Error metric in the interval [0; 100]\"\"\"\n",
    "    nominator = tf.reduce_sum(tf.abs(tf.subtract(y, y_pred)))\n",
    "    denominator = tf.add(tf.reduce_sum(tf.abs(y)), K.epsilon())\n",
    "    wape = tf.scalar_mul(100.0, tf.divide(nominator, denominator))\n",
    "    return wape\n",
    "\n",
    "def nse(y, y_pred):\n",
    "    return (1-(K.sum((y_pred-y)**2)/K.sum((y-K.mean(y))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b619b8a6-2074-4ab7-bb57-7e52e25fb1b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "Epoch 1/50\n",
      "6559/6571 [============================>.] - ETA: 0s - loss: 0.0124 - Wape: 4.5404 - MAE: 0.0124 - RMSE: 0.0249 - MAPE: 437.3267 - MSE: 6.1884e-04\n",
      "Epoch 00001: loss improved from inf to 0.01244, saving model to New Leon's LSTM Sweatwater/weights-improvement-01-0.0124.hdf5\n",
      "6571/6571 [==============================] - 15s 2ms/step - loss: 0.0124 - Wape: 4.5375 - MAE: 0.0124 - RMSE: 0.0249 - MAPE: 436.5794 - MSE: 6.1814e-04\n",
      "Epoch 2/50\n",
      "6547/6571 [============================>.] - ETA: 0s - loss: 0.0079 - Wape: 2.8807 - MAE: 0.0079 - RMSE: 0.0180 - MAPE: 387.6411 - MSE: 3.2282e-04\n",
      "Epoch 00002: loss improved from 0.01244 to 0.00791, saving model to New Leon's LSTM Sweatwater/weights-improvement-02-0.0079.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0079 - Wape: 2.8802 - MAE: 0.0079 - RMSE: 0.0180 - MAPE: 386.2758 - MSE: 3.2275e-04\n",
      "Epoch 3/50\n",
      "6551/6571 [============================>.] - ETA: 0s - loss: 0.0073 - Wape: 2.6688 - MAE: 0.0073 - RMSE: 0.0175 - MAPE: 406.8127 - MSE: 3.0470e-04\n",
      "Epoch 00003: loss improved from 0.00791 to 0.00732, saving model to New Leon's LSTM Sweatwater/weights-improvement-03-0.0073.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0073 - Wape: 2.6680 - MAE: 0.0073 - RMSE: 0.0174 - MAPE: 405.6244 - MSE: 3.0448e-04\n",
      "Epoch 4/50\n",
      "6568/6571 [============================>.] - ETA: 0s - loss: 0.0071 - Wape: 2.5979 - MAE: 0.0071 - RMSE: 0.0174 - MAPE: 431.8933 - MSE: 3.0187e-04\n",
      "Epoch 00004: loss improved from 0.00732 to 0.00712, saving model to New Leon's LSTM Sweatwater/weights-improvement-04-0.0071.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0071 - Wape: 2.5978 - MAE: 0.0071 - RMSE: 0.0174 - MAPE: 431.7420 - MSE: 3.0180e-04\n",
      "Epoch 5/50\n",
      "6555/6571 [============================>.] - ETA: 0s - loss: 0.0070 - Wape: 2.5417 - MAE: 0.0070 - RMSE: 0.0173 - MAPE: 490.5038 - MSE: 2.9876e-04\n",
      "Epoch 00005: loss improved from 0.00712 to 0.00698, saving model to New Leon's LSTM Sweatwater/weights-improvement-05-0.0070.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0070 - Wape: 2.5423 - MAE: 0.0070 - RMSE: 0.0173 - MAPE: 489.3675 - MSE: 2.9900e-04\n",
      "Epoch 6/50\n",
      "6555/6571 [============================>.] - ETA: 0s - loss: 0.0069 - Wape: 2.5167 - MAE: 0.0069 - RMSE: 0.0172 - MAPE: 557.0276 - MSE: 2.9649e-04\n",
      "Epoch 00006: loss improved from 0.00698 to 0.00691, saving model to New Leon's LSTM Sweatwater/weights-improvement-06-0.0069.hdf5\n",
      "6571/6571 [==============================] - 13s 2ms/step - loss: 0.0069 - Wape: 2.5177 - MAE: 0.0069 - RMSE: 0.0172 - MAPE: 555.7361 - MSE: 2.9654e-04\n",
      "Epoch 7/50\n",
      "6564/6571 [============================>.] - ETA: 0s - loss: 0.0069 - Wape: 2.5046 - MAE: 0.0069 - RMSE: 0.0172 - MAPE: 532.7324 - MSE: 2.9658e-04\n",
      "Epoch 00007: loss improved from 0.00691 to 0.00687, saving model to New Leon's LSTM Sweatwater/weights-improvement-07-0.0069.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0069 - Wape: 2.5051 - MAE: 0.0069 - RMSE: 0.0172 - MAPE: 532.2232 - MSE: 2.9667e-04\n",
      "Epoch 8/50\n",
      "6550/6571 [============================>.] - ETA: 0s - loss: 0.0068 - Wape: 2.4810 - MAE: 0.0068 - RMSE: 0.0172 - MAPE: 538.7775 - MSE: 2.9712e-04\n",
      "Epoch 00008: loss improved from 0.00687 to 0.00681, saving model to New Leon's LSTM Sweatwater/weights-improvement-08-0.0068.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0068 - Wape: 2.4816 - MAE: 0.0068 - RMSE: 0.0172 - MAPE: 537.1190 - MSE: 2.9693e-04\n",
      "Epoch 9/50\n",
      "6563/6571 [============================>.] - ETA: 0s - loss: 0.0068 - Wape: 2.4685 - MAE: 0.0068 - RMSE: 0.0172 - MAPE: 578.4775 - MSE: 2.9626e-04\n",
      "Epoch 00009: loss improved from 0.00681 to 0.00677, saving model to New Leon's LSTM Sweatwater/weights-improvement-09-0.0068.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0068 - Wape: 2.4681 - MAE: 0.0068 - RMSE: 0.0172 - MAPE: 577.8362 - MSE: 2.9645e-04\n",
      "Epoch 10/50\n",
      "6560/6571 [============================>.] - ETA: 0s - loss: 0.0067 - Wape: 2.4536 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 585.6482 - MSE: 2.9587e-04\n",
      "Epoch 00010: loss improved from 0.00677 to 0.00673, saving model to New Leon's LSTM Sweatwater/weights-improvement-10-0.0067.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0067 - Wape: 2.4542 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 584.7336 - MSE: 2.9613e-04\n",
      "Epoch 11/50\n",
      "6558/6571 [============================>.] - ETA: 0s - loss: 0.0067 - Wape: 2.4503 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 602.3609 - MSE: 2.9538e-04\n",
      "Epoch 00011: loss improved from 0.00673 to 0.00672, saving model to New Leon's LSTM Sweatwater/weights-improvement-11-0.0067.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0067 - Wape: 2.4505 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 601.2375 - MSE: 2.9529e-04\n",
      "Epoch 12/50\n",
      "6545/6571 [============================>.] - ETA: 0s - loss: 0.0067 - Wape: 2.4552 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 618.9430 - MSE: 2.9574e-04\n",
      "Epoch 00012: loss did not improve from 0.00672\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0067 - Wape: 2.4545 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 616.5677 - MSE: 2.9545e-04\n",
      "Epoch 13/50\n",
      "6570/6571 [============================>.] - ETA: 0s - loss: 0.0067 - Wape: 2.4374 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 594.3636 - MSE: 2.9462e-04\n",
      "Epoch 00013: loss improved from 0.00672 to 0.00668, saving model to New Leon's LSTM Sweatwater/weights-improvement-13-0.0067.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0067 - Wape: 2.4373 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 594.3354 - MSE: 2.9461e-04\n",
      "Epoch 14/50\n",
      "6556/6571 [============================>.] - ETA: 0s - loss: 0.0067 - Wape: 2.4335 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 586.2924 - MSE: 2.9423e-04\n",
      "Epoch 00014: loss improved from 0.00668 to 0.00668, saving model to New Leon's LSTM Sweatwater/weights-improvement-14-0.0067.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0067 - Wape: 2.4332 - MAE: 0.0067 - RMSE: 0.0172 - MAPE: 585.0201 - MSE: 2.9423e-04\n",
      "Epoch 15/50\n",
      "6547/6571 [============================>.] - ETA: 0s - loss: 0.0067 - Wape: 2.4259 - MAE: 0.0067 - RMSE: 0.0171 - MAPE: 581.1445 - MSE: 2.9402e-04\n",
      "Epoch 00015: loss improved from 0.00668 to 0.00665, saving model to New Leon's LSTM Sweatwater/weights-improvement-15-0.0067.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0067 - Wape: 2.4261 - MAE: 0.0067 - RMSE: 0.0171 - MAPE: 579.0919 - MSE: 2.9396e-04\n",
      "Epoch 16/50\n",
      "6546/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.4142 - MAE: 0.0066 - RMSE: 0.0171 - MAPE: 602.9533 - MSE: 2.9188e-04\n",
      "Epoch 00016: loss improved from 0.00665 to 0.00663, saving model to New Leon's LSTM Sweatwater/weights-improvement-16-0.0066.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.4158 - MAE: 0.0066 - RMSE: 0.0171 - MAPE: 600.7329 - MSE: 2.9241e-04\n",
      "Epoch 17/50\n",
      "6559/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.4019 - MAE: 0.0066 - RMSE: 0.0171 - MAPE: 614.6622 - MSE: 2.9156e-04\n",
      "Epoch 00017: loss improved from 0.00663 to 0.00659, saving model to New Leon's LSTM Sweatwater/weights-improvement-17-0.0066.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.4020 - MAE: 0.0066 - RMSE: 0.0171 - MAPE: 613.6086 - MSE: 2.9159e-04\n",
      "Epoch 18/50\n",
      "6550/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.4084 - MAE: 0.0066 - RMSE: 0.0171 - MAPE: 619.1628 - MSE: 2.9156e-04\n",
      "Epoch 00018: loss did not improve from 0.00659\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.4076 - MAE: 0.0066 - RMSE: 0.0171 - MAPE: 617.2557 - MSE: 2.9132e-04\n",
      "Epoch 19/50\n",
      "6554/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.4131 - MAE: 0.0066 - RMSE: 0.0171 - MAPE: 641.4454 - MSE: 2.9080e-04\n",
      "Epoch 00019: loss did not improve from 0.00659\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.4131 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 639.8591 - MSE: 2.9069e-04\n",
      "Epoch 20/50\n",
      "6567/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.4058 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 620.8563 - MSE: 2.9041e-04\n",
      "Epoch 00020: loss did not improve from 0.00659\n",
      "6571/6571 [==============================] - 13s 2ms/step - loss: 0.0066 - Wape: 2.4058 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 620.5444 - MSE: 2.9033e-04\n",
      "Epoch 21/50\n",
      "6554/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.4061 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 629.8453 - MSE: 2.8899e-04\n",
      "Epoch 00021: loss did not improve from 0.00659\n",
      "6571/6571 [==============================] - 13s 2ms/step - loss: 0.0066 - Wape: 2.4062 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 628.2883 - MSE: 2.8914e-04\n",
      "Epoch 22/50\n",
      "6558/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.3962 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 638.9548 - MSE: 2.8859e-04\n",
      "Epoch 00022: loss improved from 0.00659 to 0.00658, saving model to New Leon's LSTM Sweatwater/weights-improvement-22-0.0066.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.3959 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 637.7617 - MSE: 2.8856e-04\n",
      "Epoch 23/50\n",
      "6547/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.4042 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 629.4346 - MSE: 2.8849e-04\n",
      "Epoch 00023: loss did not improve from 0.00658\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.4033 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 627.2095 - MSE: 2.8824e-04\n",
      "Epoch 24/50\n",
      "6550/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.3933 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 620.7162 - MSE: 2.8732e-04\n",
      "Epoch 00024: loss improved from 0.00658 to 0.00657, saving model to New Leon's LSTM Sweatwater/weights-improvement-24-0.0066.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.3940 - MAE: 0.0066 - RMSE: 0.0170 - MAPE: 618.8050 - MSE: 2.8737e-04\n",
      "Epoch 25/50\n",
      "6566/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3851 - MAE: 0.0065 - RMSE: 0.0169 - MAPE: 632.8552 - MSE: 2.8674e-04\n",
      "Epoch 00025: loss improved from 0.00657 to 0.00655, saving model to New Leon's LSTM Sweatwater/weights-improvement-25-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3856 - MAE: 0.0065 - RMSE: 0.0169 - MAPE: 632.4415 - MSE: 2.8678e-04\n",
      "Epoch 26/50\n",
      "6554/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.3969 - MAE: 0.0066 - RMSE: 0.0169 - MAPE: 643.8779 - MSE: 2.8610e-04\n",
      "Epoch 00026: loss did not improve from 0.00655\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.3970 - MAE: 0.0066 - RMSE: 0.0169 - MAPE: 642.2856 - MSE: 2.8597e-04\n",
      "Epoch 27/50\n",
      "6552/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3869 - MAE: 0.0065 - RMSE: 0.0169 - MAPE: 626.6785 - MSE: 2.8537e-04\n",
      "Epoch 00027: loss improved from 0.00655 to 0.00655, saving model to New Leon's LSTM Sweatwater/weights-improvement-27-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3866 - MAE: 0.0065 - RMSE: 0.0169 - MAPE: 624.9384 - MSE: 2.8547e-04\n",
      "Epoch 28/50\n",
      "6552/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3788 - MAE: 0.0065 - RMSE: 0.0169 - MAPE: 650.7085 - MSE: 2.8431e-04\n",
      "Epoch 00028: loss improved from 0.00655 to 0.00652, saving model to New Leon's LSTM Sweatwater/weights-improvement-28-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3786 - MAE: 0.0065 - RMSE: 0.0169 - MAPE: 648.9013 - MSE: 2.8427e-04\n",
      "Epoch 29/50\n",
      "6554/6571 [============================>.] - ETA: 0s - loss: 0.0066 - Wape: 2.3883 - MAE: 0.0066 - RMSE: 0.0169 - MAPE: 641.1237 - MSE: 2.8444e-04\n",
      "Epoch 00029: loss did not improve from 0.00652\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0066 - Wape: 2.3876 - MAE: 0.0066 - RMSE: 0.0169 - MAPE: 639.5375 - MSE: 2.8421e-04\n",
      "Epoch 30/50\n",
      "6556/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3706 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 650.4006 - MSE: 2.8294e-04\n",
      "Epoch 00030: loss improved from 0.00652 to 0.00651, saving model to New Leon's LSTM Sweatwater/weights-improvement-30-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3713 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 648.9901 - MSE: 2.8309e-04\n",
      "Epoch 31/50\n",
      "6551/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3793 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 649.3746 - MSE: 2.8340e-04\n",
      "Epoch 00031: loss did not improve from 0.00651\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3787 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 647.4725 - MSE: 2.8349e-04\n",
      "Epoch 32/50\n",
      "6543/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3708 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 639.5861 - MSE: 2.8202e-04\n",
      "Epoch 00032: loss improved from 0.00651 to 0.00651, saving model to New Leon's LSTM Sweatwater/weights-improvement-32-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3703 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 636.9370 - MSE: 2.8212e-04\n",
      "Epoch 33/50\n",
      "6563/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3792 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 658.6510 - MSE: 2.8259e-04\n",
      "Epoch 00033: loss did not improve from 0.00651\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3790 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 657.9204 - MSE: 2.8248e-04\n",
      "Epoch 34/50\n",
      "6552/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3690 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 630.6278 - MSE: 2.8206e-04\n",
      "Epoch 00034: loss improved from 0.00651 to 0.00650, saving model to New Leon's LSTM Sweatwater/weights-improvement-34-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3683 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 628.8902 - MSE: 2.8190e-04\n",
      "Epoch 35/50\n",
      "6549/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3723 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 650.8427 - MSE: 2.8156e-04\n",
      "Epoch 00035: loss did not improve from 0.00650\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3734 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 648.7415 - MSE: 2.8195e-04\n",
      "Epoch 36/50\n",
      "6569/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3734 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 631.4878 - MSE: 2.8210e-04\n",
      "Epoch 00036: loss did not improve from 0.00650\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3736 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 631.3623 - MSE: 2.8211e-04\n",
      "Epoch 37/50\n",
      "6566/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3761 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 643.9800 - MSE: 2.8169e-04\n",
      "Epoch 00037: loss did not improve from 0.00650\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3759 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 643.5588 - MSE: 2.8172e-04\n",
      "Epoch 38/50\n",
      "6570/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3730 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 655.3925 - MSE: 2.8173e-04\n",
      "Epoch 00038: loss did not improve from 0.00650\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3728 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 655.3615 - MSE: 2.8171e-04\n",
      "Epoch 39/50\n",
      "6557/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3729 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 641.9466 - MSE: 2.8149e-04\n",
      "Epoch 00039: loss did not improve from 0.00650\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3736 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 640.6514 - MSE: 2.8153e-04\n",
      "Epoch 40/50\n",
      "6569/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3693 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 645.5490 - MSE: 2.8099e-04\n",
      "Epoch 00040: loss improved from 0.00650 to 0.00650, saving model to New Leon's LSTM Sweatwater/weights-improvement-40-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3692 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 645.4203 - MSE: 2.8096e-04\n",
      "Epoch 41/50\n",
      "6567/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3710 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 641.4022 - MSE: 2.8143e-04\n",
      "Epoch 00041: loss did not improve from 0.00650\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3716 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 641.0803 - MSE: 2.8157e-04\n",
      "Epoch 42/50\n",
      "6546/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3716 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 630.5541 - MSE: 2.8109e-04\n",
      "Epoch 00042: loss did not improve from 0.00650\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3722 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 628.2309 - MSE: 2.8098e-04\n",
      "Epoch 43/50\n",
      "6545/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3647 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 664.8157 - MSE: 2.8082e-04\n",
      "Epoch 00043: loss improved from 0.00650 to 0.00649, saving model to New Leon's LSTM Sweatwater/weights-improvement-43-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3658 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 662.2648 - MSE: 2.8076e-04\n",
      "Epoch 44/50\n",
      "6568/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3599 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 645.8744 - MSE: 2.8069e-04\n",
      "Epoch 00044: loss improved from 0.00649 to 0.00648, saving model to New Leon's LSTM Sweatwater/weights-improvement-44-0.0065.hdf5\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3603 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 645.6480 - MSE: 2.8069e-04\n",
      "Epoch 45/50\n",
      "6557/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3804 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 658.4499 - MSE: 2.8068e-04\n",
      "Epoch 00045: loss did not improve from 0.00648\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3801 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 657.1202 - MSE: 2.8065e-04\n",
      "Epoch 46/50\n",
      "6553/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3608 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 646.1147 - MSE: 2.8058e-04\n",
      "Epoch 00046: loss did not improve from 0.00648\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3606 - MAE: 0.0065 - RMSE: 0.0167 - MAPE: 644.4188 - MSE: 2.8045e-04\n",
      "Epoch 47/50\n",
      "6566/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3691 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 653.5949 - MSE: 2.8086e-04\n",
      "Epoch 00047: loss did not improve from 0.00648\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3689 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 653.1675 - MSE: 2.8092e-04\n",
      "Epoch 48/50\n",
      "6568/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3610 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 645.1550 - MSE: 2.8117e-04\n",
      "Epoch 00048: loss did not improve from 0.00648\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3609 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 644.9286 - MSE: 2.8112e-04\n",
      "Epoch 49/50\n",
      "6566/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3721 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 649.5046 - MSE: 2.8084e-04\n",
      "Epoch 00049: loss did not improve from 0.00648\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3725 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 649.0800 - MSE: 2.8085e-04\n",
      "Epoch 50/50\n",
      "6569/6571 [============================>.] - ETA: 0s - loss: 0.0065 - Wape: 2.3636 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 651.3389 - MSE: 2.8088e-04\n",
      "Epoch 00050: loss did not improve from 0.00648\n",
      "6571/6571 [==============================] - 12s 2ms/step - loss: 0.0065 - Wape: 2.3637 - MAE: 0.0065 - RMSE: 0.0168 - MAPE: 651.2095 - MSE: 2.8089e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x154d24142d50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "# The LSTM architecture\n",
    "regressor = Sequential()\n",
    "# First LSTM layer with Dropout regularisation\n",
    "regressor.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "# # Third LSTM layer\n",
    "regressor.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "# The Fifth layer\n",
    "regressor.add(Flatten())\n",
    "\n",
    "# The Sixth layer\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer=\"adam\",loss=\"mean_absolute_error\",\n",
    "                  metrics=[Wape,\n",
    "                           tf.metrics.MeanAbsoluteError(name=\"MAE\"),\n",
    "                           tf.metrics.RootMeanSquaredError(name=\"RMSE\"),\n",
    "                           tf.metrics.MeanAbsolutePercentageError(name=\"MAPE\"),\n",
    "                           \"MSE\",\n",
    "                          ],\n",
    "                           \n",
    "                 )\n",
    "\n",
    "print(1)\n",
    "filepath=\"New Leon's LSTM Sweatwater/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "print(1)\n",
    "# Fitting to the training set\n",
    "regressor.fit(X_train,y_train,epochs=50,batch_size=32,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f5ecd-52a9-410e-ab95-4631871890b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor.fit(X_train,y_train,epochs=50,batch_size=32,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70fac47-43c7-4393-9fc6-2ad3ad7bf129",
   "metadata": {},
   "source": [
    "# Create Model and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45d2d43b-3469-46cc-b1da-3b7a6e385e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_model():\n",
    "    regressor = Sequential()\n",
    "# First LSTM layer with Dropout regularisation\n",
    "    regressor.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "    # # Third LSTM layer\n",
    "    regressor.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "    # The Fifth layer\n",
    "    regressor.add(Flatten())\n",
    "\n",
    "    # The Sixth layer\n",
    "    regressor.add(Dense(units=1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "    regressor.compile(optimizer=\"adam\",loss=\"mean_absolute_error\",\n",
    "                      metrics=[Wape,\n",
    "                               tf.metrics.MeanAbsoluteError(name=\"MAE\"),\n",
    "                               tf.metrics.RootMeanSquaredError(name=\"RMSE\"),\n",
    "                               tf.metrics.MeanAbsolutePercentageError(name=\"MAPE\"),\n",
    "                               \"MSE\",\n",
    "                              ],\n",
    "\n",
    "                     )\n",
    "\n",
    "    return regressor\n",
    "regressor = create_model()\n",
    "regressor.load_weights(\"New Leon's LSTM Sweatwater/weights-improvement-44-0.0065.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b4b8ff5-d8be-4faa-952c-4e9f21a439e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save(\"Columbus-CNN.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
