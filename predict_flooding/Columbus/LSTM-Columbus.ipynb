{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1becc4d0-aa48-42e2-97c4-550538fd8d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17b83a1-dc52-40d0-99c6-7dbfa17eaf1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../../datasets/chattahoochee-columbus.csv',header=0, parse_dates=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d99384d-7f9c-4163-945b-64dad3e3b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/spackages/linux-centos8-x86_64/gcc-8.3.1/anaconda3-2019.10-v5cuhr6keyz5ryxcwvv2jkzfj2gwrj4a/lib/python3.7/site-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14822a220250>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "plt.plot(df.index,df[\"height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84b6da5-b7c7-45b9-8971-82ee6ad9a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[:'2020'].iloc[:,:]\n",
    "test_set = df['2021':].iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da42284-7380-412f-8f7d-b49b9c5680d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "training_set_scaled = sc.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecccaa4a-5633-4888-86e8-86e4fd4b8c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210350"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "050ac6d7-8bbe-4077-8a06-269c6297c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(100,len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-100:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d938e1d6-1d8e-48e2-aa72-3b56c952ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "223780cc-9f7e-4f37-bd11-a537e07cccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210250, 100, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96091a9c-a00f-49ed-86d1-145a2c9f2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping X_train for efficient modelling\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62a6a62-9cc1-4c1d-b5c7-e993becf4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84abc51a-e30a-4292-b48b-0121676b773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d4a6bcf-ba1f-40b7-a576-8f3f5af0c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wape(y, y_pred):\n",
    "    \"\"\"Weighted Average Percentage Error metric in the interval [0; 100]\"\"\"\n",
    "    nominator = tf.reduce_sum(tf.abs(tf.subtract(y, y_pred)))\n",
    "    denominator = tf.add(tf.reduce_sum(tf.abs(y)), K.epsilon())\n",
    "    wape = tf.scalar_mul(100.0, tf.divide(nominator, denominator))\n",
    "    return wape\n",
    "\n",
    "def nse(y, y_pred):\n",
    "    return (1-(K.sum((y_pred-y)**2)/K.sum((y-K.mean(y))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b619b8a6-2074-4ab7-bb57-7e52e25fb1b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "Epoch 1/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0066 - Wape: 2.4046 - MAE: 0.0066 - RMSE: 0.0146 - MAPE: 28.5479 - MSE: 2.1316e-04\n",
      "Epoch 00001: loss improved from inf to 0.00661, saving model to New Leon's/weights-improvement-01-0.0066.hdf5\n",
      "6571/6571 [==============================] - 569s 86ms/step - loss: 0.0066 - Wape: 2.4046 - MAE: 0.0066 - RMSE: 0.0146 - MAPE: 28.5479 - MSE: 2.1316e-04\n",
      "Epoch 2/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0038 - Wape: 1.3883 - MAE: 0.0038 - RMSE: 0.0077 - MAPE: 9.1925 - MSE: 5.8615e-05\n",
      "Epoch 00002: loss improved from 0.00661 to 0.00381, saving model to New Leon's/weights-improvement-02-0.0038.hdf5\n",
      "6571/6571 [==============================] - 564s 86ms/step - loss: 0.0038 - Wape: 1.3883 - MAE: 0.0038 - RMSE: 0.0077 - MAPE: 9.1925 - MSE: 5.8615e-05\n",
      "Epoch 3/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0036 - Wape: 1.2978 - MAE: 0.0036 - RMSE: 0.0075 - MAPE: 5.2666 - MSE: 5.6143e-05\n",
      "Epoch 00003: loss improved from 0.00381 to 0.00356, saving model to New Leon's/weights-improvement-03-0.0036.hdf5\n",
      "6571/6571 [==============================] - 564s 86ms/step - loss: 0.0036 - Wape: 1.2978 - MAE: 0.0036 - RMSE: 0.0075 - MAPE: 5.2666 - MSE: 5.6143e-05\n",
      "Epoch 4/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0034 - Wape: 1.2418 - MAE: 0.0034 - RMSE: 0.0074 - MAPE: 43.1237 - MSE: 5.4465e-05\n",
      "Epoch 00004: loss improved from 0.00356 to 0.00341, saving model to New Leon's/weights-improvement-04-0.0034.hdf5\n",
      "6571/6571 [==============================] - 564s 86ms/step - loss: 0.0034 - Wape: 1.2418 - MAE: 0.0034 - RMSE: 0.0074 - MAPE: 43.1237 - MSE: 5.4465e-05\n",
      "Epoch 5/50\n",
      "4613/6571 [====================>.........] - ETA: 2:48 - loss: 0.0033 - Wape: 1.2181 - MAE: 0.0033 - RMSE: 0.0074 - MAPE: 15.5587 - MSE: 5.4169e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-ff3ccf794f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Fitting to the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/software/venv/tf_gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "# The LSTM architecture\n",
    "regressor = Sequential()\n",
    "# First LSTM layer with Dropout regularisation\n",
    "regressor.add(LSTM(units=264, return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "\n",
    "# Second LSTM layer\n",
    "regressor.add(LSTM(units=132,return_sequences=True))\n",
    "\n",
    "# # Third LSTM layer\n",
    "regressor.add(LSTM(units=64,return_sequences=True))\n",
    "\n",
    "# # Fouth LSTM layer\n",
    "regressor.add(LSTM(units=32))\n",
    "\n",
    "\n",
    "# The Fifth layer\n",
    "regressor.add(Dense(units=30))\n",
    "\n",
    "# The Sixth layer\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer=\"adam\",loss=\"mean_absolute_error\",\n",
    "                  metrics=[Wape,\n",
    "                           tf.metrics.MeanAbsoluteError(name=\"MAE\"),\n",
    "                           tf.metrics.RootMeanSquaredError(name=\"RMSE\"),\n",
    "                           tf.metrics.MeanAbsolutePercentageError(name=\"MAPE\"),\n",
    "                           \"MSE\",\n",
    "                          ],\n",
    "                           \n",
    "                 )\n",
    "\n",
    "print(1)\n",
    "filepath=\"New Leon\\'s/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "print(1)\n",
    "# Fitting to the training set\n",
    "regressor.fit(X_train,y_train,epochs=50,batch_size=32,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f5ecd-52a9-410e-ab95-4631871890b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115599.9609 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1329.3271 - MSE: 0.0147\n",
      "Epoch 00001: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 566s 86ms/step - loss: 0.0993 - Wape: 115599.9609 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1329.3271 - MSE: 0.0147\n",
      "Epoch 2/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115628.6641 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1325.5287 - MSE: 0.0147\n",
      "Epoch 00002: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115628.6641 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1325.5287 - MSE: 0.0147\n",
      "Epoch 3/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115608.0703 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1333.0856 - MSE: 0.0147\n",
      "Epoch 00003: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115608.0703 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1333.0856 - MSE: 0.0147\n",
      "Epoch 4/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115588.3047 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1316.7043 - MSE: 0.0147\n",
      "Epoch 00004: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115588.3047 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1316.7043 - MSE: 0.0147\n",
      "Epoch 5/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115605.9453 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1361.2439 - MSE: 0.0147\n",
      "Epoch 00005: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115605.9453 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1361.2439 - MSE: 0.0147\n",
      "Epoch 6/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115606.0234 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1328.3129 - MSE: 0.0147\n",
      "Epoch 00006: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115606.0234 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1328.3129 - MSE: 0.0147\n",
      "Epoch 7/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115594.6641 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1341.4708 - MSE: 0.0147\n",
      "Epoch 00007: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115594.6641 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1341.4708 - MSE: 0.0147\n",
      "Epoch 8/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115605.8047 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1348.2112 - MSE: 0.0147\n",
      "Epoch 00008: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115605.8047 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1348.2112 - MSE: 0.0147\n",
      "Epoch 9/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115615.1562 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1340.0397 - MSE: 0.0147\n",
      "Epoch 00009: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115615.1562 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1340.0397 - MSE: 0.0147\n",
      "Epoch 10/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115596.3281 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1347.1393 - MSE: 0.0147\n",
      "Epoch 00010: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115596.3281 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1347.1393 - MSE: 0.0147\n",
      "Epoch 11/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115587.0469 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1334.2235 - MSE: 0.0147\n",
      "Epoch 00011: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115587.0469 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1334.2235 - MSE: 0.0147\n",
      "Epoch 12/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115621.3906 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1341.5258 - MSE: 0.0147\n",
      "Epoch 00012: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115621.3906 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1341.5258 - MSE: 0.0147\n",
      "Epoch 13/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115616.7266 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1338.8575 - MSE: 0.0147\n",
      "Epoch 00013: loss did not improve from 0.09926\n",
      "6571/6571 [==============================] - 569s 87ms/step - loss: 0.0993 - Wape: 115616.7266 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1338.8575 - MSE: 0.0147\n",
      "Epoch 14/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115600.3984 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1332.6030 - MSE: 0.0147\n",
      "Epoch 00014: loss improved from 0.09926 to 0.09925, saving model to New Leon's/weights-improvement-14-0.0993.hdf5\n",
      "6571/6571 [==============================] - 566s 86ms/step - loss: 0.0993 - Wape: 115600.3984 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1332.6030 - MSE: 0.0147\n",
      "Epoch 15/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115594.5547 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1324.7910 - MSE: 0.0147\n",
      "Epoch 00015: loss did not improve from 0.09925\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115594.5547 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1324.7910 - MSE: 0.0147\n",
      "Epoch 16/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115615.0000 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1319.7074 - MSE: 0.0147\n",
      "Epoch 00016: loss did not improve from 0.09925\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115615.0000 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1319.7074 - MSE: 0.0147\n",
      "Epoch 17/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115600.6250 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1322.5215 - MSE: 0.0147\n",
      "Epoch 00017: loss did not improve from 0.09925\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115600.6250 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1322.5215 - MSE: 0.0147\n",
      "Epoch 18/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115603.8984 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1353.1708 - MSE: 0.0147\n",
      "Epoch 00018: loss did not improve from 0.09925\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115603.8984 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1353.1708 - MSE: 0.0147\n",
      "Epoch 19/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115615.9922 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1326.6948 - MSE: 0.0147\n",
      "Epoch 00019: loss did not improve from 0.09925\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115615.9922 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1326.6948 - MSE: 0.0147\n",
      "Epoch 20/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115611.1328 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1348.6498 - MSE: 0.0147\n",
      "Epoch 00020: loss did not improve from 0.09925\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115611.1328 - MAE: 0.0993 - RMSE: 0.1213 - MAPE: 1348.6498 - MSE: 0.0147\n",
      "Epoch 21/50\n",
      "6571/6571 [==============================] - ETA: 0s - loss: 0.0993 - Wape: 115594.1719 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1320.8120 - MSE: 0.0147\n",
      "Epoch 00021: loss did not improve from 0.09925\n",
      "6571/6571 [==============================] - 565s 86ms/step - loss: 0.0993 - Wape: 115594.1719 - MAE: 0.0993 - RMSE: 0.1212 - MAPE: 1320.8120 - MSE: 0.0147\n",
      "Epoch 22/50\n",
      "3403/6571 [==============>...............] - ETA: 4:32 - loss: 0.0995 - Wape: 115813.3203 - MAE: 0.0995 - RMSE: 0.1219 - MAPE: 45.4952 - MSE: 0.0149"
     ]
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train,epochs=50,batch_size=32,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70fac47-43c7-4393-9fc6-2ad3ad7bf129",
   "metadata": {},
   "source": [
    "# Create Model and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45d2d43b-3469-46cc-b1da-3b7a6e385e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_model():\n",
    "    regressor = Sequential()\n",
    "    # First LSTM layer with Dropout regularisation\n",
    "    regressor.add(LSTM(units=264, return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "\n",
    "    # Second LSTM layer\n",
    "    regressor.add(LSTM(units=132,return_sequences=True))\n",
    "\n",
    "    # # Third LSTM layer\n",
    "    regressor.add(LSTM(units=64,return_sequences=True))\n",
    "\n",
    "    # # Fouth LSTM layer\n",
    "    regressor.add(LSTM(units=32))\n",
    "\n",
    "\n",
    "    # The Fifth layer\n",
    "    regressor.add(Dense(units=30))\n",
    "\n",
    "    # The Sixth layer\n",
    "    regressor.add(Dense(units=1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "    regressor.compile(optimizer=\"adam\",loss=\"mean_absolute_error\",\n",
    "                      metrics=[Wape,\n",
    "                               tf.metrics.MeanAbsoluteError(name=\"MAE\"),\n",
    "                               tf.metrics.RootMeanSquaredError(name=\"RMSE\"),\n",
    "                               tf.metrics.MeanAbsolutePercentageError(name=\"MAPE\"),\n",
    "                               \"MSE\",\n",
    "                              ],\n",
    "\n",
    "                     )\n",
    "    return regressor\n",
    "regressor = create_model()\n",
    "regressor.load_weights(\"weights-improvement-44-0.0022.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b4b8ff5-d8be-4faa-952c-4e9f21a439e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save(\"Columbus-LSTM.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
